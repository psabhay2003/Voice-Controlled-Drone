{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22524079",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = \"./whisper-drone-command-final\"\n",
    "SAMPLE_RATE = 16000\n",
    "SECONDS = 5\n",
    "FORCE_ENGLISH = True\n",
    "DEFAULT_DISTANCE = 10.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37974ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import re\n",
    "from difflib import get_close_matches\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import librosa\n",
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write as wav_write\n",
    "\n",
    "import nltk\n",
    "# nltk.download(\"punkt\", quiet=True)\n",
    "# nltk.download(\"punkt_tab\", quiet=True)\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "import spacy\n",
    "from transformers import WhisperForConditionalGeneration, WhisperProcessor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b481cd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_audio(seconds = SECONDS, fs = SAMPLE_RATE):\n",
    "    print(f\"Recording {seconds}s at {fs} Hz mono...\")\n",
    "    rec = sd.rec(int(seconds * fs), samplerate=fs, channels=1, dtype=\"float32\")\n",
    "    sd.wait()\n",
    "    print(\"Done.\")\n",
    "    return rec.flatten()\n",
    "\n",
    "\n",
    "def save_wav(path, audio, fs = SAMPLE_RATE):\n",
    "    wav_write(path, fs, (audio * 32767).astype(\"int16\"))\n",
    "    print(f\"Saved WAV: {path}\")\n",
    "\n",
    "\n",
    "def trim_silence(audio, top_db=30):\n",
    "    y, _ = librosa.effects.trim(audio, top_db=top_db)\n",
    "    return y if y.size > 0 else audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "077167fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from ./whisper-drone-command-final on cpu...\n"
     ]
    }
   ],
   "source": [
    "def load_model_and_processor(model_dir = MODEL_DIR):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"loading model from {model_dir} on {device}...\")\n",
    "    processor = WhisperProcessor.from_pretrained(model_dir)\n",
    "    model = WhisperForConditionalGeneration.from_pretrained(model_dir).to(device).eval()\n",
    "    return model, processor, device\n",
    "\n",
    "\n",
    "@torch.inference_mode()\n",
    "def transcribe_audio_array(\n",
    "    audio_f32_mono_16k: np.ndarray,\n",
    "    model: WhisperForConditionalGeneration,\n",
    "    processor: WhisperProcessor,\n",
    "    device,\n",
    "    force_english = FORCE_ENGLISH,\n",
    "    max_new_tokens = 64,\n",
    "):\n",
    "    if audio_f32_mono_16k.ndim != 1:\n",
    "        audio_f32_mono_16k = librosa.to_mono(audio_f32_mono_16k.T)\n",
    "    audio_f32_mono_16k = trim_silence(audio_f32_mono_16k, top_db=30)\n",
    "\n",
    "    \n",
    "    feats = processor.feature_extractor(\n",
    "        audio_f32_mono_16k, sampling_rate=SAMPLE_RATE, return_tensors=\"pt\"\n",
    "    )\n",
    "    input_features = feats.input_features.to(device)\n",
    "    attention_mask = feats.get(\"attention_mask\")\n",
    "    if attention_mask is not None:\n",
    "        attention_mask = attention_mask.to(device)\n",
    "    gen_kwargs = {}\n",
    "    if force_english:\n",
    "        try:\n",
    "            gen_kwargs[\"forced_decoder_ids\"] = processor.get_decoder_prompt_ids(\n",
    "                language=\"english\", task=\"transcribe\"\n",
    "            )\n",
    "        except Exception:\n",
    "            pass\n",
    "    t0 = time.time()\n",
    "    pred_ids = model.generate(\n",
    "        input_features,\n",
    "        attention_mask=attention_mask,\n",
    "        do_sample=False,\n",
    "        temperature=0.0,\n",
    "        num_beams=1,\n",
    "        length_penalty=0.0,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        **gen_kwargs,\n",
    "    )\n",
    "    dt = time.time() - t0\n",
    "\n",
    "    raw_text = processor.batch_decode(pred_ids, skip_special_tokens=True)[0]\n",
    "    return raw_text, dt\n",
    "\n",
    "model, processor, device = load_model_and_processor(MODEL_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2085945d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONNECTOR_PAT = re.compile(r\"\\b(?:and then|then|and)\\b\", flags=re.IGNORECASE)\n",
    "\n",
    "def heuristic_split_commands(text):\n",
    "    t = \" \".join(text.strip().split())\n",
    "\n",
    "    preliminary = [s.strip() for s in sent_tokenize(t) if s.strip()]\n",
    "\n",
    "    segments: list[str] = []\n",
    "    for seg in preliminary if preliminary else [t]:\n",
    "        parts = [p.strip() for p in CONNECTOR_PAT.split(seg) if p.strip()]\n",
    "        segments.extend(parts)\n",
    "    cleaned = []\n",
    "    for s in segments:\n",
    "        s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "        s = re.sub(r\"\\.{2,}$\", \".\", s) \n",
    "        s = re.sub(r\"\\s*\\.\\s*$\", \".\", s)        \n",
    "        if not re.search(r\"[.!?]$\", s):\n",
    "            s = s + \".\"                         \n",
    "        cleaned.append(s)\n",
    "    return cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e838b8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "CANONICAL_DIRECTIONS = {\"left\", \"right\", \"up\", \"down\"}\n",
    "DIRECTION_SYNONYMS = {\n",
    "    \"left\": {\n",
    "        \"left\", \"leftward\", \"leftwards\", \"leftside\", \"left-side\", \"left side\",\n",
    "        \"port\", \"lft\", \"to the left\"\n",
    "    },\n",
    "    \"right\": {\n",
    "        \"right\", \"rightward\", \"rightwards\", \"rightside\", \"right-side\", \"right side\",\n",
    "        \"starboard\", \"rgt\", \"to the right\"\n",
    "    },\n",
    "    \"up\": {\n",
    "        \"up\", \"upward\", \"upwards\", \"ascend\", \"rise\", \"climb\", \"higher\", \"elevate\",\n",
    "        \"gain altitude\", \"go above\", \"above\", \"increase altitude\"\n",
    "    },\n",
    "    \"down\": {\n",
    "        \"down\", \"downward\", \"downwards\", \"descend\", \"lower\", \"drop\", \"decrease\",\n",
    "        \"reduce altitude\", \"below\", \"go below\"\n",
    "    },\n",
    "}\n",
    "\n",
    "WORD2CANON = {}\n",
    "for canon, words in DIRECTION_SYNONYMS.items():\n",
    "    for w in words:\n",
    "        WORD2CANON[w] = canon\n",
    "\n",
    "\n",
    "class LemmaFuzzyExtractor:\n",
    "    def __init__(self):\n",
    "        self.nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n",
    "\n",
    "    def normalize_direction(self, text, cutoff = 0.75):\n",
    "        doc = self.nlp(text.lower())\n",
    "        tokens = [t.text for t in doc if t.is_alpha]\n",
    "        lemmas = [t.lemma_ for t in doc if t.is_alpha]\n",
    "        terms = tokens + lemmas\n",
    "        for w in terms:\n",
    "            if w in WORD2CANON:\n",
    "                return WORD2CANON[w]\n",
    "\n",
    "        vocab = list(WORD2CANON.keys())\n",
    "        for w in terms:\n",
    "            m = get_close_matches(w, vocab, n=1, cutoff=cutoff)\n",
    "            if m:\n",
    "                return WORD2CANON[m[0]]\n",
    "\n",
    "        return None\n",
    "\n",
    "    def extract_distance_meters(self, text):\n",
    "        tl = text.lower()\n",
    "        patterns = [\n",
    "            (r'(\\d+(?:\\.\\d+)?)\\s*(?:meter|metre|meters|metres|m\\b)', 1.0),\n",
    "            (r'(\\d+(?:\\.\\d+)?)\\s*(?:foot|feet|ft\\b)', 0.3048),\n",
    "            (r'(\\d+(?:\\.\\d+)?)\\s*(?:kilometer|kilometers|kilometres|km)\\b', 1000.0),\n",
    "        ]\n",
    "        for pat, factor in patterns:\n",
    "            m = re.search(pat, tl)\n",
    "            if m:\n",
    "                return float(m.group(1)) * factor\n",
    "        nums = re.findall(r'\\b(\\d+(?:\\.\\d+)?)\\b', text)\n",
    "        for n in nums:\n",
    "            v = float(n)\n",
    "            if 0.1 <= v <= 1000:\n",
    "                return v\n",
    "\n",
    "        return None\n",
    "\n",
    "\n",
    "def extract_direction_distance_json(text):\n",
    "    sentences = heuristic_split_commands(text)\n",
    "    extractor = LemmaFuzzyExtractor()\n",
    "    outputs: list[dict] = []\n",
    "\n",
    "    for s in sentences:\n",
    "        direction = extractor.normalize_direction(s)\n",
    "        distance = extractor.extract_distance_meters(s)\n",
    "        if direction is not None and distance is None:\n",
    "            distance = DEFAULT_DISTANCE\n",
    "        if direction is None and distance is None:\n",
    "            outputs.append({\"sentence\": s, \"direction\": \"\", \"distance\": None})\n",
    "        else:\n",
    "            outputs.append({\"sentence\": s, \"direction\": direction, \"distance\": distance})\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "be9b7dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording 5s at 16000 Hz mono...\n",
      "Done.\n",
      "Saved WAV: mic_audio.wav\n",
      " drone you need to move towards left by 10 meters and go above 5 meters\n",
      "\n",
      "Time: 0.314s on cpu\n",
      "\n",
      "=== Direction/Distance JSON ===\n",
      "[\n",
      "  {\n",
      "    \"sentence\": \"drone you need to move towards left by 10 meters.\",\n",
      "    \"direction\": \"left\",\n",
      "    \"distance\": 10.0\n",
      "  },\n",
      "  {\n",
      "    \"sentence\": \"go above 5 meters.\",\n",
      "    \"direction\": \"up\",\n",
      "    \"distance\": 5.0\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "audio = record_audio(seconds=SECONDS, fs=SAMPLE_RATE)\n",
    "save_wav(\"mic_audio.wav\", audio, fs=SAMPLE_RATE)\n",
    "\n",
    "raw_text, latency = transcribe_audio_array(audio, model, processor, device, force_english=FORCE_ENGLISH)\n",
    "print(raw_text)\n",
    "print(f\"\\nTime: {latency:.3f}s on {device}\")\n",
    "extracted = extract_direction_distance_json(raw_text)\n",
    "print(\"\\n=== Direction/Distance JSON ===\")\n",
    "print(json.dumps(extracted, ensure_ascii=False, indent=2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datafiles",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
